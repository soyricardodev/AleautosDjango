# üö® SOLUCI√ìN URGENTE - EJECUTAR EN ESTE ORDEN

## üî¥ ERROR CR√çTICO ACTUAL: CAN'T START NEW THREAD

```
RuntimeError: can't start new thread
```

**El sistema no puede crear m√°s threads.** Esto ocurre porque ASGI (UvicornWorker) crea demasiados threads.

### ‚ö° SOLUCI√ìN INMEDIATA (EJECUTAR PRIMERO):

```bash
# 1. Aumentar l√≠mite de threads (temporal)
echo 32768 | sudo tee /proc/sys/kernel/threads-max

# 2. Reducir workers de Gunicorn (URGENTE)
sudo systemctl edit gunicorn
```

**Pega esto en el editor:**
```ini
[Service]
ExecStart=
ExecStart=/opt/AleautosDjango/.venv/bin/gunicorn \
  --access-logfile - \
  -k uvicorn.workers.UvicornWorker \
  --workers 1 \
  --threads 8 \
  --limit-concurrency 100 \
  --timeout 120 \
  --bind unix:/run/gunicorn.sock \
  proyectoBallena.asgi:application
LimitNPROC=4096
LimitNOFILE=65536
TasksMax=4096
```

**Luego:**
```bash
sudo systemctl daemon-reload
sudo systemctl restart gunicorn
```

**O usar el script autom√°tico:**
```bash
bash scripts/fix_thread_limit.sh
bash scripts/reducir_workers_gunicorn.sh
```

**üí° RECOMENDACI√ìN: Si no necesitas async, cambia a WSGI** (ver `LEEME_PRIMERO_THREADS.md`)

Ver `SOLUCION_CANT_START_NEW_THREAD.md` o `LEEME_PRIMERO_THREADS.md` para m√°s detalles.

---

## ‚ö†Ô∏è ERROR ANTERIOR: TIMEOUT EXPIRED

```
connection to server at "127.0.0.1", port 5432 failed: timeout expired
```

**PostgreSQL no est√° respondiendo** dentro del tiempo l√≠mite.

### ‚ö° SOLUCI√ìN INMEDIATA PARA TIMEOUT:

```bash
# 1. Verificar estado de PostgreSQL
bash scripts/verificar_postgres_docker.sh

# 2. Si est√° ca√≠do, iniciarlo
docker-compose up -d db

# 3. Si est√° activo pero no responde, reiniciarlo
docker-compose restart db

# 4. Reiniciar Gunicorn (para aplicar nuevo timeout de 30 segundos)
sudo systemctl restart gunicorn
```

**‚úÖ Ya actualic√© el timeout de 10 a 30 segundos en `settings.py`**

Ver `LEEME_PRIMERO_TIMEOUT.md` o `SOLUCION_TIMEOUT_POSTGRES.md` para m√°s detalles.

---

## ‚ö†Ô∏è PROBLEMA CR√çTICO: OTRO PROCESO CON FUGA MASIVA

**PID 2167175 tiene 599,786 archivos abiertos** - ¬°OTRA FUGA MASIVA!

Adem√°s, PostgreSQL en Docker tiene l√≠mite de 100 conexiones y est√° lleno.

---

## üîÑ OPCI√ìN R√ÅPIDA: REINICIAR EL VPS

**Si tienes m√∫ltiples procesos problem√°ticos y quieres una soluci√≥n inmediata:**

```bash
sudo reboot
```

**Despu√©s del reinicio**, ejecuta los pasos 5-8 de abajo para aplicar las correcciones permanentes.

Ver `GUIA_REINICIO_VPS.md` para detalles completos.

---

## ‚ö° COMANDOS A EJECUTAR (Copiar y pegar en orden)

### 1. Matar el proceso problem√°tico (INMEDIATO)
```bash
sudo kill -9 2167175
```

O usar el script autom√°tico:
```bash
sudo bash scripts/matar_proceso_fuga.sh 2167175
```

### 2. Aumentar l√≠mite temporalmente
```bash
ulimit -n 65536
```

### 3. Liberar conexiones de PostgreSQL (Docker)
```bash
bash scripts/liberar_conexiones_postgres_docker.sh
```

### 4. Reiniciar Gunicorn (para aplicar el c√≥digo corregido)
```bash
sudo systemctl restart gunicorn
```

### 5. Aumentar l√≠mite de conexiones en PostgreSQL (PERMANENTE)

**Opci√≥n A: Usar docker-compose.yaml actualizado** (ya est√° modificado)
```bash
docker-compose down
docker-compose up -d db
```

**Opci√≥n B: Configurar manualmente**
```bash
sudo bash scripts/configurar_postgres_docker.sh
```

### 6. Configurar Gunicorn permanentemente
```bash
cd /opt/AleautosDjango
sudo bash scripts/fix_gunicorn_systemd.sh
```

### 7. Aumentar l√≠mite de archivos permanentemente
```bash
sudo bash scripts/aumentar_ulimit.sh
```

### 8. Verificar que se solucion√≥
```bash
bash scripts/diagnostico_completo.sh
```

---

## üìã QU√â HACE CADA PASO

**Paso 1**: Mata el worker con 599,786 archivos abiertos (fuga masiva)

**Paso 2**: Aumenta el l√≠mite de archivos abiertos temporalmente (efecto inmediato)

**Paso 3**: Libera conexiones inactivas de PostgreSQL en Docker

**Paso 4**: Reinicia Gunicorn para que cargue el c√≥digo corregido (conexiones HTTP ahora se cierran)

**Paso 5**: Aumenta `max_connections` de PostgreSQL de 100 a 200 (evita "too many clients already")

**Paso 6**: 
- Actualiza tu servicio systemd de Gunicorn
- Reduce workers de 3 a 2
- Agrega `LimitNOFILE=65536`
- Agrega `--max-requests 1000` para reciclar workers
- Reinicia Gunicorn autom√°ticamente

**Paso 7**: Configura el l√≠mite permanentemente en `/etc/security/limits.conf`

**Paso 8**: Verifica que todo est√© funcionando correctamente

---

## ‚ö†Ô∏è IMPORTANTE

- **El c√≥digo ya est√° corregido** - las conexiones HTTP ahora se cierran correctamente
- **docker-compose.yaml ya est√° actualizado** - `max_connections=200` configurado
- Despu√©s del **Paso 4**, Gunicorn cargar√° el c√≥digo corregido
- Despu√©s del **Paso 5**, PostgreSQL aceptar√° hasta 200 conexiones simult√°neas
- El script del **Paso 6** hace backup autom√°tico de tu configuraci√≥n
- Si algo sale mal, puedes restaurar desde el backup

---

## üîç VERIFICACI√ìN R√ÅPIDA

```bash
# Ver l√≠mite actual
ulimit -n
# Debe mostrar 65536

# Ver estado de Gunicorn
sudo systemctl status gunicorn

# Ver archivos abiertos por cada worker (debe ser < 1000)
for pid in $(pgrep -f gunicorn); do
    echo "PID $pid: $(lsof -p $pid 2>/dev/null | grep -v WARNING | grep -v 'can't stat' | wc -l) archivos"
done

# Ver conexiones de PostgreSQL
bash scripts/liberar_conexiones_postgres_docker.sh
```

---

## üìö DOCUMENTACI√ìN COMPLETA

- `SOLUCION_POSTGRES_DOCKER.md` - Soluci√≥n espec√≠fica para PostgreSQL en Docker
- `SOLUCION_URGENTE_FUGA_MASIVA.md` - Detalles del problema de fuga de archivos
- `EJECUTAR_ESTOS_COMANDOS.md` - Gu√≠a detallada paso a paso
- `SOLUCION_PASO_A_PASO.md` - Explicaci√≥n completa
- `SOLUCION_TOO_MANY_OPEN_FILES.md` - Soluci√≥n t√©cnica detallada

---

## üéØ CAMBIOS APLICADOS EN EL C√ìDIGO

‚úÖ **Rifa/views.py** - `enviarWhatsapp()` ahora cierra conexiones HTTP  
‚úÖ **Rifa/apis.py** - `testWhatsapp()` ahora cierra conexiones HTTP  
‚úÖ **docker-compose.yaml** - `max_connections=200` configurado  
‚úÖ **Scripts creados** - Para matar procesos problem√°ticos y liberar conexiones
